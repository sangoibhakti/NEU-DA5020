---
title: "Assignment 7"
author: "Bhakti Sangoi"
date: "February 25, 2018"
output: pdf_document
---

#Libraries
```{r}
library(png)
library(readxl)
```

#GitHub
- https://github.com/sangoibhakti/NEU-DA5020.git


#Questions
##A.	(50 Points) Pick at least 2 web scraping toolkits (either automated tools like Import.io or R packages such as rvest) and try to use them to extract data from the Yelp website. In particular, create a search in Yelp to find good burger restaurants in the Boston area. You must try out at least two toolkits, but you will use only one to actually extract and save the full data

###Solution

Two web scraping toolkits tried are:
1) Instant Data Scarper
2) Grepsr

Instant Data Scarper is easy to use and quite fast, hence I continued this assignment using Instant Data Scarper


##B.	(20 points) Import the data you extracted into a data frame in R. Your data frame should have exactly 30 rows, and each row represents a burger restaurant in Boston.

###Solution

###1) Open https://www.yelp.com/boston. Search for Burgers and limit Boston neighborhoods to Allston, Brighton, Back Bay, Beacon Hill, Downtown Area, Fenway, South End, and West End.
```{r}
image1 <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/yelp_filter.png")
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(image1,0,0,1,1)
```

###2) Renaming the column heading and selecting the required columns to be scraped.
```{r}
image2 <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/instant_scraper1.png")
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(image2,0,0,1,1)
```

###3) Selecting how many pages to crawl and then scraping 3 pages for 30 rows.
```{r}
image3 <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/instant_scraper2.png")
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(image3,0,0,1,1)
```

###4) Downloading in csv format and then Viewing the csv file
```{r}
csv_image <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/yelp_csv.png")
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(csv_image,0,0,1,1)
```

###5)Reading the csv file
```{r}
yelp_dataset <- read.csv("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/yelp_scraper.csv")
View(yelp_dataset)
```

##C.	(30 Points) Write a report that compares the tools with a focus on cost, ease of use, features, and your recommendation. Discuss your experience with the tools and why you decided to use the one you picked in the end. Use screenshots of toolkits and your scraping process to support your statements.  Also include a screenshot or an excerpt of your data in the report.

###Solution

Instant Data Scraper and Grepsr both are found in Google chrome extension. 

###Grepsr Toolkit
###Cost:
It can be downloaded for free. It has different monthly plans. It has free plan which helps in creating 3 free reports per month.
```{r}
grepsr_cost <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/grepsr_cost.png")
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(grepsr_cost,0,0,1,1)
```

###Ease of Use:
It is readily available. It is a quick google chrome extension. Also has a tour guide.  

###Features:
Once you select the page you want to scrap, you first select the tags that need to be extracted. 
Further it has different options of pagination like "Next link"", "infinite scroll"" and "load more button".
Then you can extract and download the data in different formats such as csv,JSON, XML, Excel formats
There are different downloading options by sending it via dropbox, google drive, dropbox.
Scrap the data and then group it accordingly.
```{r}
grepsr_selection <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/grepsr_selection.png")
grepsr_pagination <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/grepsr_pagination.png")
grepsr_fileformat <- readPNG("C:/Users/sango/Documents/Desktop/R/Assignments/Assignment 7/grepsr_fileformat.png")
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(grepsr_selection,0,0,1,1)
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(grepsr_pagination,0,0,1,1)
plot(0:1,0:1,type="n",ann=FALSE,axes=FALSE)
rasterImage(grepsr_fileformat,0,0,1,1)

```

###Instant Data Scarper
###Cost
It can be downloaded for free. Activate the extension. There is no cost to it.

###Ease of Use
It is readily available for free. It is very user friendly and all the features are easy to understand and use.

###Features
Select the page you want to scrap, click on instant data scraper google extension.
Extension will guess where the data is. Edit the column heading. There is an option to try another table button to guess again.
To scrap another page, there is an option for "Locate next"
Then start crawling the number of pages you want to scrap. 
Delete the unwanted fields anytime during scraping.
Download it in csv or excel.

###Comparing
Instant Data Scraper came out to be very user friendly. One can easily edit, remove unwanted columns and use it. It is very quick. It guesses all the required data very well.
Grepsr is little time consuming in selecting what tags are needed for scraping. It was many different format options to save data. But pagination is tricky to understand. Both are google chrome extensions.

###Recommendation
Grepsr should have better documentation or tour guide on how to use. It should be more user friendly. It should improve its options to scrap more pages together. Also it should have some guessing crawler data options which becomes faster and easy for user.


##D.	(10 points) Within your report describe what you have derived about the URL for yelp pages. What are the differences between the three URLs? What are the parameters that determined your search query (Boston burger restaurants in 8 selected neighborhoods)? What is(are) the parameter(s) used for pagination? Without opening Yelp.com in the browser, what is your guess of the URL for the 7th page of Chinese restaurants in New York?

###3 URL's used for scraping first three pages:
1) https://www.yelp.com/search?find_desc=Burger&start=0&l=p:MA:Boston::%5BAllston/Brighton,Back_Bay,Beacon_Hill,Downtown,Fenway,South_End,West_End%5D
2) https://www.yelp.com/search?find_desc=Burger&start=10&l=p:MA:Boston::%5BAllston/Brighton,Back_Bay,Beacon_Hill,Downtown,Fenway,South_End,West_End%5D
3) https://www.yelp.com/search?find_desc=Burger&start=20&l=p:MA:Boston::%5BAllston/Brighton,Back_Bay,Beacon_Hill,Downtown,Fenway,South_End,West_End%5D

###Difference between above three URL's
Difference between all the three links is the start tag. in case of page 1: start=0 ,in case of page 2: start=10  and in case of page 3: start=20. 

###Parameters 
In the above URL, 3 parameters are seen.
1) "find_desc: Burger": This is the category of food served. It means finding restaurants that serve burger.
2) "start=0"= Page 1,"start=10"= Page 2, : This is Pagination. It leads to the page you have requested for. It can also mean "start=0" i.e. Page 1 has 10 search. next 10 are found in page 2 and next 10 in page 3.
3) MA:Boston::%5BAllston/Brighton,Back_Bay,Beacon_Hill,Downtown,Fenway,South_End,West_End: Filter on location. Finding restaurants which are only located in the above neighborhood.

###URL for the 7th page of Chinese restaurants in New York.
https://www.yelp.com/search?find_desc=Chinese&start=60&l=p:NY:New_York



